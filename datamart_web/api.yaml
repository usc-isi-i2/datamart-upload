openapi: 3.0.2
info:
  title: ISI Datamart Link Panel
  version: 0.0.2
  contact:
    name: API Support
    email: supprt@example.com
#servers:
#  - url: http://dsbox02.isi.edu:9000
#    description: Main (production) server
  # - url: http://staging-api.example.com
  #   description: Optional server description, e.g. Internal staging server for testing
paths:
  /wikifier:
    post:
      tags:
        - Search API
      summary: Do wikifier before search
      description: 'The method chooses which column and which method you want to do wikifier. <br><br> One parameters is required: <br> **data**: The supplied data (a path to the csv file or a d3m dataset id). <br> <br> Four parameters are optional: <br> **format**: Return format (csv format or d3m format with metadata). <br> **column**: specifies which column from the complementary datamart dataset to append to the supplied data. If not given, all columns are append. <br> **wikifier_choice**: specifies which method you want to wikify a column. If columns not given, it will choose automatic by default. If you want to wikify a numeric column, please choose identifier. If you want to wikify a text column, please choose new_wikifier. If you do not know which one to use, please choose automatic. <br> **threshold**: minimum coverage ratio for a wikidata columns to be appended.'
      requestBody:
        content:
          application/json:
            schema:
              type: array
              items:
                type: object
                properties:
                  column:
                    type: integer
                  wikifier_choice:
                    type: string
            examples:
              example_for_not_specified:
                value: null
              example_for_test_search_data:
                value:
                  - column: 1
                    wikifier_choice: identifier
                  - column: 2
                    wikifier_choice: new_wikifier
                  - column: 3
                    wikifier_choice: new_wikifier
                  - column: 5
                    wikifier_choice: identifier
                description: 'column is an optional parameter, an integer indicates the list of column indices from the Datamart dataset that should be appended. If not given, all possible columns will be appended and it will choose automatic wikifier method by default.<br> wikifier_choice is an optional parameter, it includes three choices: identifier, new_wikifier and automatic. If you want to wikify a numeric column, please choose identifier. If you want to wikify a text column, please choose new_wikifier. If you do not know which one to use, please choose automatic.'
      parameters:
        - in: query
          name: data
          description: '<p>Supplied data file. It could be a filepath or a d3m dataset id (for example: "DA_poverty_estimation"). </p>'
          schema:
            type: string
          required: true
          examples:
            filepath:
              value: https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_search_data.csv
            d3m-dataset-id:
              value: DA_poverty_estimation
        - in: query
          name: format
          description: Optional parameter, download format(general csv format or d3m format), default is csv.
          required: false
          schema:
            type: string
            enum: [csv, d3m]
        - in: query
          name: threshold
          description: Optional parameter, minimum coverage ratio for a wikidata columns to be appended. The range is (0,1) and default is 0.7.
          required: false
          schema:
            type: number
          example: 0.7
      responses:
        '200':
          description: A zip file
          content:
            application/zip:
              schema:
                 type: string
                 format: binary
        '404':
          description: Not found.
  /search:
    post:
      tags:
        - Search API
      summary: Search
      description: 'The main search method for the ISI Datamart. This method typically is the first method to call.  <br > Currently, only the supplied_data parameter is necessary and the JSON query parameter does not influence search process. <br> <br> One parameter is required:<br> **data**: It could be a path to a csv file or a d3m dataset id (for example: "DA_poverty_estimation"). <br> <br> Two parameters are optional:<br> **max_return_docs**: An int indicating how many results to return. If not given, the default value is 20. <br> **query**: A JSON query to specify additional search requirements (ignored for now).'
      parameters:
        - in: query
          name: query
          description: The query
          schema:
            type: string
        - in: query
          name: max_return_docs
          description: Max return docs (default 20 if not given)
          schema:
            type: integer
          example: 20
        - in: query
          name: data
          description: '<p>Supplied data file. It could be a d3m-dataset-id or a filepath</p>'
          schema:
            type: string
          required: true
          examples:
            filepath:
              value: https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_search_data.csv
            d3m-dataset-id:
              value: DA_poverty_estimation
        - in: query
          name: run_wikifier
          description: whether to run wikifier on supplied data or not. Default value is true. If not run wikifier, the search speed will be quicker but the wikidata related parts will be missed.
          schema:
            type: string
            enum: [true, false]
      responses:
        '200':
          description: successful operation
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/SearchResult'
        '404':
          description: Not found.

  /search_without_data:
    post:
      tags:
        - Search API
      summary: Search by keywords or variables
      description: 'Searching datasets by keywords or variables. <br> <br>One parameter is required: <br> **keywords**: Keywords that match a dataset. <br> <br>One parameter is optional: <br> **variables**: It could be one of temporal_variable, geospatial_variable, tabular_variable and named_entity_variable. For now, just temporal_variable could be used.'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Query'
            examples:
              not_use_variables:
                value: null
              temporal_variable:
                value:
                  variables:
                    temporal_variable:
                      start: 2018-01-01T01
                      end: 2018-07-01T01
                      granularity: hour
                description: "Describes columns containing temporal information. DateTime format could be: '2019-01' or '2019-01-01' or '2019-01-01T10:10:10', and granularity should be 'month', 'day', 'second' respectively"
      parameters:
        - in: query
          name: keywords
          description: Keywords that match a dataset. In each item, input one keyword.
          required: true
          schema:
            type: array
            items:
              type: string
          style: form
          explode: false
          example: ['Date', 'Dewpoint', 'Wind']
      responses:
        '200':
          description: successful operation
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/SearchResult'
        '404':
          description: Not found.

  /augment:
    post:
      tags:
        - Augment API
      summary: Augment dataset
      description: 'The method augments the given dataset using a search result returned by the Search API. <br>This method only returns the rows of the dataset that matches well with the complementary datamart dataset. If no rows can be joined, an error is raised.<br> <br> Three parameters are required: <br> **task**: An item in string format from the search result list return by the Search API. <br> **data**: The supplied data (a path to the csv file or a d3m dataset id). <br> **format**: Return format (csv format or d3m format with metadata). <br> <br> Two parameters are optional: <br> **destination**: If given, the system saves the augmented dataset to the given path, and returns the path. If not given, it returns the results to user as download function. <br> **columns**: specifies which columns from the complementary datamart dataset to append to the supplied data. If not given, all columns are append. '
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                task:
                  type: string
                  description: 'The search result task (json-like str) from Search API you can try to copy the content from <a href="https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/sample_search_result_wikidata.txt">example1</a> or <a href="https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/sample_search_result_general.txt">example2</a>'
              required:
                - task
      parameters:
        - in: query
          name: data
          description: '<p>Supplied data file. It could be a d3m-dataset-id or a filepath</p>'
          schema:
            type: string
          required: true
          examples:
            filepath:
              value: https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_search_data.csv
            d3m-dataset-id:
              value: DA_poverty_estimation
        - in: query
          name: format
          description: Download format(general csv format or d3m format)
          required: true
          schema:
            type: string
            enum: [csv, d3m]
        - in: query
          name: columns
          schema:
            type: array
            items:
              type: integer
          style: form
          explode: false
          example: [1, 3]
          description: Optional parameter, a str indicate the list of column indices from the Datamart dataset that should be appended. See format example below, If not given, all possible columns from search results will be appended. In each item, input one integer.
        - in: query
          name: destination
          schema:
            type: string
          description: If given, the augmented results(in csv or d3m) will be saved to the given path. If not given, the augmented result will be returned to the user for download. See the example for the destination format
          example: /Users/claire/Desktop
        - in: query
          name: run_wikifier
          description: whether to run wikifier on supplied data and search result(only applied for genearl search results) or not. Default value is true. The download will failed if the joining hint columns are adapted from wikifier's columns.
          schema:
            type: string
            enum: [true, false]
      responses:
        '200':
          description: A zip file
          content:
            application/zip:
              schema:
                 type: string
                 format: binary
        '404':
          description: Not found.

  /download:
    post:
      tags:
        - Download API
      summary: Download
      description: 'The method downloads the datamart dataset specified by a search result returned by the Search API method. <br>This method only returns rows of the dataset that matches well with the complementary datamart dataset. If no rows can be joined, an error is raised. <br><br> Three parameters are required: <br> **task**: An item in string format from the search result list return by the Search API. <br> **data**: The supplied data (a path to the csv file or a d3m dataset id). <br>  **format**: Return format (csv format or d3m format with metadata).'
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                task:
                  type: string
                  description: 'The search result task (json-like str) from Search API you can try to copy the content from <a href="https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/sample_search_result_wikidata.txt">example1</a> or <a href="https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/sample_search_result_general.txt">example2</a>'
              required:
                - task
      parameters:
        - in: query
          name: data
          description: '<p>Supplied data file. It could be a d3m-dataset-id or a filepath</p>'
          schema:
            type: string
          required: true
          examples:
            filepath:
              value: https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_search_data.csv
            d3m-dataset-id:
              value: DA_poverty_estimation
        - in: query
          name: format
          description: Download format(general csv format or d3m format)
          required: true
          schema:
            type: string
            enum: [csv, d3m]
        - in: query
          name: run_wikifier
          description: whether to run wikifier on supplied data and search result(only applied for genearl search results) or not. Default value is true. The download will failed if the joining hint columns are adapted from wikifier's columns.
          schema:
            type: string
            enum: [true, false]
      responses:
        '200':
          description: A zip file
          content:
            application/zip:
              schema:
                 type: string
                 format: binary
        '404':
          description: Not found.

  /download_metadata/{id}:
    get:
      tags:
        - Download API
      summary: Download the dataset metadata with given id
      description: 'The method downloads the datamart dataset metadata associated with the datamart id. Different from the /download/{id} method, this method returns the dataset metadata. <br>If a wikidata format id is given, it will return maximum 100 random Q nodes with those properties metadata. <br><br>One parameter is required: <br> **id**: The datamart id, can be found from search result.'
      parameters:
        - in: path
          name: id
          description: ID of datamart
          required: true
          schema:
            type: string
          examples:
            example 1:
              value: D20eb2d7f-aafb-443e-8bf2-132ef103e98b
            example 2:
              value: wikidata_search_on___P1082___P2046___P571___with_column_FIPS_wikidata
      responses:
        '200':
          description: array
          content:
            application/json:
              schema:
                 type: array
                 items:
                  $ref: '#/components/schemas/Metadata'
        '404':
          description: Not found.

  /download/{id}:
    get:
      tags:
        - Download API
      summary: Download the dataset with given id
      description: 'The method downloads the datamart dataset associated with the datamart id. Different from the /download method, this method returns the whole dataset without join hint columns. <br> If a wikidata format id is given, it will return maximum 100 random Q nodes with those properties. <br> <br>Two parameters are required: <br> **id**: The datamart id, can be found from search result. <br> **format**: Return format (csv format or d3m format with metadata).'
      parameters:
        - in: path
          name: id
          description: ID of datamart
          required: true
          schema:
            type: string
          examples:
            example 1:
              value: D20eb2d7f-aafb-443e-8bf2-132ef103e98b
            example 2:
              value: wikidata_search_on___P1082___P2046___P571___with_column_FIPS_wikidata
        - in: query
          name: format
          description: Download format(general csv format or d3m format)
          required: true
          schema:
            type: string
            enum: [csv, d3m]
      responses:
        '200':
          description: A zip file
          content:
            application/zip:
              schema:
                 type: string
                 format: base64
        '404':
          description: Not found.

  /upload:
    post:
      tags:
        - Upload API
      summary: Upload dataset with metadata
      description: 'ALL-IN-ONE upload method that takes as input the url of the dataset resource to be uploaded, the type of the dataset resource, and optional dataset-level property parameters.<br> The method automatically generates the dataset metadata and upload the dataset with the generated metadata to datamart database. This is the RECOMMEND method to upload datasets. <br> <br> Two required method parameters are: <br> **url/file**: The address to the dataset resource. Or upload a file from local. One of the paramters on **url** or **file** have to be given. <br> **file_type**: A string indicating the type of the data source, currently only "online_csv" is available. '
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                upload_file:
                  type: string
                  format: binary
                  description: 'Dataset file (.csv) need to upload to datamart'
      parameters:
        - in: query
          name: url
          schema:
            type: string
          example: https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_upload_data.csv
          # required: true
          description: Url of input file
        # - in: formData
        #   name: upload_file
        #   schema:
        #     type: file
        #   description: The file of the dataset to upload to datamart
        - in: query
          name: run_wikifier
          description: 'whether to run wikifier on the uploaded dataset or not. <br> Default value is auto. Wikifier step will skip if the size(row number * column number) of the dataset is larger than **100000**'
          schema:
            type: string
            example: auto
            enum: [auto, true, false]
        - name: file_type
          in: query
          schema:
            type: string
            enum:
              - online_csv
          required: true
          description: Online file type, currently only support online_csv
        - name: title
          in: query
          schema:
            type: string
          required: false
          description: 'Name of the dataset, if the url contains multiple dataset, please provide each title, split with mark "||". <br> For example, title1||title2'
        - name: description
          in: query
          schema:
            type: string
          required: false
          description: 'Description of the dataset, if the url contains multiple dataset, please provide each description, split with mark "||". <br> For example, This is description for first dataset||This is description for second dataset'
        - name: keywords
          in: query
          schema:
            type: string
          required: false
          description: 'Keywords or tags to describe the dataset content, if the url contains multiple dataset, please provide each keywords, split with mark "||". <br> For example, keywords1_1, keywords1_2||keywords2_1, keywords2_2'
        - name: username
          in: query
          schema:
            type: string
          required: true
          description: the username for the upload user
        - name: password
          in: query
          schema:
            type: string
            format: password
          required: true
          description: the password for the upload user
      responses:
        '200':
          description: successful operation
          content:
            application/text:
              schema:
                type: string
        '404':
          description: Not found.

  /upload/test:
    post:
      tags:
        - Upload API
      summary: Upload dataset with metadata
      description: 'ALL-IN-ONE upload method that takes as input the url of the dataset resource to be uploaded, the type of the dataset resource, and optional dataset-level property parameters.<br> The method automatically generates the dataset metadata and upload the dataset with the generated metadata to datamart database. This is the RECOMMEND method to upload datasets. <br> <br> Two required method parameters are: <br> **url/file**: The address to the dataset resource. Or upload a file from local. One of the paramters on **url** or **file** have to be given. <br> **file_type**: A string indicating the type of the data source, currently only "online_csv" is available. '
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                upload_file:
                  type: string
                  format: binary
                  description: 'Dataset file (.csv) need to upload to datamart'
      parameters:
        - in: query
          name: url
          schema:
            type: string
          example: https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_upload_data.csv
          # required: true
          description: Url of input file
        # - in: formData
        #   name: upload_file
        #   schema:
        #     type: file
        #   description: The file of the dataset to upload to datamart
        - in: query
          name: run_wikifier
          description: 'whether to run wikifier on the uploaded dataset or not. <br> Default value is auto. Wikifier step will skip if the size(row number * column number) of the dataset is larger than **100000**'
          schema:
            type: string
            example: auto
            enum: [auto, true, false]
        - name: file_type
          in: query
          schema:
            type: string
            enum:
              - online_csv
          required: true
          description: Online file type, currently only support online_csv
        - name: title
          in: query
          schema:
            type: string
          required: false
          description: 'Name of the dataset, if the url contains multiple dataset, please provide each title, split with mark "||". <br> For example, title1||title2'
        - name: description
          in: query
          schema:
            type: string
          required: false
          description: 'Description of the dataset, if the url contains multiple dataset, please provide each description, split with mark "||". <br> For example, This is description for first dataset||This is description for second dataset'
        - name: keywords
          in: query
          schema:
            type: string
          required: false
          description: 'Keywords or tags to describe the dataset content, if the url contains multiple dataset, please provide each keywords, split with mark "||". <br> For example, keywords1_1, keywords1_2||keywords2_1, keywords2_2'
        - name: username
          in: query
          schema:
            type: string
          required: true
          description: the username for the upload user
        - name: password
          in: query
          schema:
            type: string
            format: password
          required: true
          description: the password for the upload user
      responses:
        '200':
          description: successful operation
          content:
            application/text:
              schema:
                type: string
        '404':
          description: Not found.

  /upload/check_upload_status:
    post:
      tags:
        - Upload API
      summary: an api used to check the uploading status
      description: 'This function is used for user to check the processes of uploading'
      parameters:
        - in: query
          name: job_ids
          schema:
            type: string
          example: 'c6b7b967-aa75-47e4-b206-ec3447fbc90c'
          required: false
          description: the job ids of the uploading processes
      responses:
        '200':
          description: successful operation
          content:
            application/text:
              schema:
                type: string
        '404':
          description: Not found.

  /upload/add_upload_user:
    post:
      tags:
        - Upload API
      summary: an api used to add upload user
      description: 'This function is used for adding user for uploading datasets'
      parameters:
        - name: token
          in: query
          schema:
            type: string
          required: true
          description: token for access to create user account
          example: ''
        - name: username
          in: query
          schema:
            type: string
          required: true
          description: username of the account
          example: ''
        - name: password
          in: query
          schema:
            type: string
          required: true
          description: password of the account
          example: ''
      responses:
        '200':
          description: successful operation
          content:
            application/text:
              schema:
                type: string
        '1000':
          description: failed.

  /upload/generateWD+Metadata:
    post:
      tags:
        - Upload API
      summary: Generate wikified dataset and its metadata
      description: 'This method is the first part of the two-part detailed upload process. This method materializes the dataset resource given by the url,  performs entity resolution using Wikidata, augments the dataset with columns based on the entity resolution, and it returns the augmented dataset along with the metadata. <br>User can check and edit the results, and then submit them using the /upload/uploadWD+Metadata endpoint. <br>This method returns two list, first is a list of the materialized csv results, the second is a list of json file which indicates the WD+ metadata.<br><br> Two parameters are required: <br>**url**: The link to the target file. <br> **file_type**: A string indicate which type of the uploaded object is, currently only online_csv is available. '
      parameters:
        - name: url
          in: query
          schema:
            type: string
          required: true
          description: Url of input file
          example: 'https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/test_upload_data.csv'
        - name: file_type
          in: query
          schema:
            type: string
            enum:
              - online_csv
          required: true
          description: Online file type, currently only support online_csv
      responses:
        '200':
          description: successful operation
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProcessResult'
        '404':
          description: Not found.
  /upload/uploadWD+Metadata:
    post:
      tags:
        - Upload API
      summary: upload data and metadata
      description: 'Second part of the two-part detailed upload process, the function uses the dataset and metadata returned from "/generateWD+Metadata" method and uploads them to datamart database.<br><br> Two parameters are required: <br>**data_input**: A list of items from materialized csv results from step 1. <br> **file_type**: A list of items from the WD+ metadata from step 1.'
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                data_input:
                  type: string
                  description: 'Data(in list format) from /upload/generateWD+Metadata api, you can try to copy the content from <a href="https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/sample_upload_part1_data.txt">here</a>'
                metadata:
                  type: string
                  description: 'Metadata(in list format) from /upload/generateWD+Metadata api, you can try to copy the content from <a href="https://raw.githubusercontent.com/usc-isi-i2/datamart-upload/d3m/datamart_web/sample_upload_part1_metadata.txt">here</a>'
              required:
                - data_input
                - metadata
      responses:
        '200':
          description: successful operation
          content:
            application/text:
              schema:
                type: string
        '404':
          description: Not found.

  /embeddings/fb/{qnode}:
    get:
      tags:
        - Embeddings API
      summary: Fetch the FB embeddings for QNODE(s)
      description: '<p>The method fetches the FB embeddings for a given qnode(s)</p>'
      parameters:
        - name: qnode
          in: path
          schema:
            type: array
            items:
              type: string
          style: simple
          explode: false
          example: [Q738200, Q717195]
          required: true
          description: "<p>a list of Wikidata QNodes</p>"
      responses:
        '200':
          description: A csv file
          content:
            application/zip:
              schema:
                 type: string
                 format: binary
        '404':
          description: Not found.
components:
  schemas:
    SearchResult:
      type: object
      properties:
        summary:
          type: object
          properties:
            title:
              type: string
            Datamart ID:
              type: string
            Score:
              type: number
            Url:
              type: string
            Columns:
              type: array
              items:
                type: string
            Recommend Join Columns:
              type: string
        datamart_id:
          type: string
        score:
          type: number
        materialize_info:
          type: object
          properties:
            id:
              type: string
            score:
              type: number
            metadata:
              type: object
              properties:
                connection_url:
                  type: string
                search_result:
                  type: object
                  properties:
                    p_nodes_needed:
                      type: array
                      items:
                        type: string
                    target_q_node_column_name:
                      type: string
                query_json:
                  type: string
                search_type:
                  type: string
            augmentation:
              type: object
              properties:
                properties:
                  type: string
                left_columns:
                  type: array
                  items:
                    type: integer
                right_columns:
                  type: array
                  items:
                    type: integer
                datamart_type:
                  type: string
        metadata:
          $ref: '#/components/schemas/Metadata'
    Metadata:
      type: array
      items:
        type: object
        properties:
          selector:
            type: array
            items:
              type: string
          metadata:
            type: object
            properties:
              structural_type:
                type: string
              semantic_types:
                type: array
                items:
                  type: string
              dimension:
                type: object
                properties:
                  name:
                    type: string
                  semantic_types:
                    type: array
                    items:
                      type: string
                  length:
                    type: integer
              name:
                type: string
    ProcessResult:
      type: object
      properties:
        data:
          type: array
          items:
            type: string
        metadata:
          type: array
          items:
            type: object
            properties:
              datamart_id:
                type: string
              materialization:
                type: object
                properties:
                  python_path:
                    type: string
                  arguments:
                    type: object
                    properties:
                      url:
                        type: string
                      file_type:
                        type: string
              variables:
                type: array
                items:
                  type: object
                  properties:
                    datamart_id:
                      type: string
                    semantic_type:
                      type: array
                      items:
                        type: string
                    name:
                      type: string
                    description:
                      type: string
                    named_entity:
                      type: array
                      items:
                        type: string
                    temporal_coverage:
                      type: object
                      properties:
                        start:
                          type: string
                        end:
                          type: string
              title:
                type: string
              description:
                type: string
              keywords:
                type: array
                items:
                  type: string
              url:
                type: string
              file_type:
                type: string
              xpath:
                type: string
    Query:
      type: object
      properties:
        variables:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/TemporalVariable'
              # - $ref: '#/components/schemas/geospatial_variable'
              # - $ref: '#/components/schemas/tabular_variable'
              # - $ref: '#/components/schemas/named_entity_variable'
    TemporalVariable:
      type: object
      description: "Describes columns containing temporal information. DateTime format could be: '2019-01' or '2019-01-01' or '2019-01-01T10:10:10', and granularity should be 'month', 'day', 'second'"
      properties:
        start:
          type: string
          description: "Requested dates are more recent than this date."
        end:
          type: string
          description: "Requested dates are older than this date."
        granularity:
          type: string
          description: "Requested dates should match the requested granularity. For example, if 'day' is requested, the best match is a dataset with dates; however a dataset with hours is relevant too as hourly data can be aggregated into days."
          enum: [year, month,day,hour,minute,second]
tags:
  - name: Search API
  - name: Download API
  - name: Augment API
  - name: Upload API
  - name: Embeddings API